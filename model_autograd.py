# -*- coding: utf-8 -*-
""".ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lzDPk3Dij3Q34ufYt1g1Pc0fICJUDVbB
"""

import torch
from sklearn.datasets import fetch_california_housing
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Load dataset
data = fetch_california_housing()
X = data.data       # shape: (20640, 8)
y = data.target     # shape: (20640,)

# Normalize features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Convert to PyTorch tensors
X = torch.tensor(X, dtype=torch.float32)
y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # shape: (N, 1)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Use only a small batch to start
X_batch = X_train[:32]
y_batch = y_train[:32]

"""step-1:create your own model class"""

import torch
import torch.nn as nn
torch.manual_seed(42)

class MyRegression(nn.Module):
    def __init__(self):
        super().__init__()
        self.hidden=nn.Linear(8,3)
        self.output=nn.Linear(3,1)
    def forward(self,x):
        x=self.hidden(x)
        x=torch.relu(x)
        x=self.output(x)
        return x

"""Step-2:Initialize the model"""

model=MyRegression()

"""Step-3:Setup loss function and optimizers"""

loss_fn=nn.MSELoss()
optimizer=torch.optim.SGD(model.parameters(),lr=0.01)

"""Step:4 Training loop(100 epoches)"""

loss_history=[]
epoches=100
for epoch in range(epoches):
    # Farword pass
    y_pred=model(X_batch)
    # Compute loss
    loss=loss_fn(y_pred,y_batch)
    loss_history.append(loss.item())
    # backpropogation
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

import matplotlib.pyplot as plt

plt.plot(loss_history)
plt.title("Training Loss (Autograd)")
plt.xlabel("Epoch")
plt.ylabel("MSE")
plt.grid(True)
plt.show()

# Put model in evaluation mode (disables dropout/batchnorm if used)
model.eval()

# Turn off gradient tracking (faster + cleaner)
with torch.no_grad():
    y_test_pred = model(X_test)

for i in range(10):
    pred = y_test_pred[i].item()
    true = y_test[i].item()
    print(f"Prediction: {pred:.2f} â€” Actual: {true:.2f}")

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 4))
plt.scatter(y_test.numpy(), y_test_pred.numpy(), alpha=0.5)
plt.xlabel("True Values")
plt.ylabel("Predicted Values")
plt.title("Prediction vs Actual (Test Set)")
plt.grid(True)
plt.plot([0, 5], [0, 5], '--', color='gray')  # ideal line
plt.show()

test_loss = nn.MSELoss()(y_test_pred, y_test)
print(f"Test MSE: {test_loss.item():.4f}")